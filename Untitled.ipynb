{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db9dae9-43b1-4989-8faf-528957094a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aadcda65-ac86-406a-8177-3cb3e9a10444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff570c85-c584-46dd-a133-24283b07ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff857365-e7bf-47fe-8c98-11a3423463cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(train_df['comment_text'])\n",
    "test_features = vectorizer.transform(test_df['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d565b970-bb2a-4b44-a737-16cd60d91eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d8001f1-f657-46d9-a2db-d0d726e52b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_features, train_df[['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']])\n",
    "test_pred = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9bf7c26-9747-46d7-b21f-e2c976e0799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.916, F1-score: 0.687\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_df[['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']], test_pred)\n",
    "f1 = f1_score(test_df[['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']], test_pred, average='weighted')\n",
    "print(f'Accuracy: {accuracy:.3f}, F1-score: {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff29644e-cc55-4c05-a590-35f861fa1094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'identity_hate': 0, 'insult': 0, 'obscene': 0, 'severe_toxic': 0, 'threat': 0, 'toxic': 0}\n",
      "\n",
      "{'identity_hate': 0, 'insult': 0, 'obscene': 0, 'severe_toxic': 0, 'threat': 0, 'toxic': 0}\n",
      "\n",
      "{'identity_hate': 0, 'insult': 0, 'obscene': 0, 'severe_toxic': 0, 'threat': 0, 'toxic': 0}\n",
      "\n",
      "{'identity_hate': 0, 'insult': 0, 'obscene': 0, 'severe_toxic': 0, 'threat': 0, 'toxic': 1}\n",
      "\n",
      "{'identity_hate': 0, 'insult': 0, 'obscene': 0, 'severe_toxic': 0, 'threat': 0, 'toxic': 0}\n",
      "\n",
      "{'identity_hate': 0, 'insult': 0, 'obscene': 0, 'severe_toxic': 0, 'threat': 0, 'toxic': 0}\n",
      "\n",
      "{'identity_hate': 0, 'insult': 1, 'obscene': 1, 'severe_toxic': 0, 'threat': 0, 'toxic': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_names = ['identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic']\n",
    "\n",
    "\n",
    "new_comments = ['The effort she had to pour into this must have been monumental. We cant thank Gura enough. Her and everyone involved. What a show',\n",
    "                'Id nominate Gura for an Oscar, I genuinely could not tell if she passed elementary math or if its all an act.',\n",
    "                'The showcase was genuinely so funny and entertaining. Thanks to everyone involved! ',\n",
    "                'Gura is a whore, she only deserves to give me a blowjob',\n",
    "                'No one really likes Gura, I cant wait to see her death',\n",
    "                'you deserve to starve, the nazis should have killed you inferior peoples',\n",
    "                'you are a bunch of bitch for American whores',\n",
    "               ]\n",
    "new_features = vectorizer.transform(new_comments)\n",
    "new_pred = clf.predict(new_features)\n",
    "pred_dict_list = []\n",
    "for i in range(len(new_comments)):\n",
    "    pred_dict = {}\n",
    "    pred_labels = new_pred[i]\n",
    "    for j in range(len(label_names)):\n",
    "        pred_dict[label_names[j]] = pred_labels[j]\n",
    "    pred_dict_list.append(pred_dict)\n",
    "\n",
    "for i in pred_dict_list:\n",
    "    print(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae094fe8-5f55-4aaf-82c7-70ef935affae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571cec16-adba-4992-9fd0-17daa10e87d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
